{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Needed Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: if you want to change precision or device of JAX, the best way to do it is to follow (as an example)\n",
    "#### `conda activate <your env name>`\n",
    "#### `conda env config vars set JAX_ENABLE_X64=True`\n",
    "#### `conda env config vars set jax_platform_name=cpu`\n",
    "#### `conda activate <your env name>`\n",
    "#### Make sure to restart VScode or jupyter notebook after this! `jax.config.update()` may or may not work because I define default jax arrays in different places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import jax, torch\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as jar\n",
    "# jax.config.update('jax_platform_name', 'cuda')\n",
    "# jax.config.update(\"jax_enable_x64\", False)\n",
    "from pandora import nf_dist\n",
    "import numpy as np\n",
    "from pandora import models, utils, GWBFunctions\n",
    "from pandora import LikelihoodCalculator as LC\n",
    "from enterprise_extensions.model_utils import get_tspan\n",
    "import pickle, json, os, corner, glob, random, copy, time, inspect\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "hist_settings = dict(\n",
    "    bins = 40,\n",
    "    histtype = 'step',\n",
    "    lw = 3,\n",
    "    density = True\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ...\n",
    "with open(datadir + f'v1p1_de440_pint_bipm2019.pkl', 'rb') as fin:\n",
    "    psrs = pickle.load(fin)\n",
    "psrlist = [psr.name for psr in psrs]\n",
    "with open(datadir + f'v1p1_all_dict.json', 'r') as fin:\n",
    "    noise_dict = json.load(fin)\n",
    "inc_ecorr = True\n",
    "backend = 'backend'\n",
    "tnequad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency-bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tspan = get_tspan(psrs) # The time-span of the entire PTA\n",
    "crn_bins = 5 # number of frequency-bins for the GWB\n",
    "int_bins = 30 # number of frequency-bins for the non-GWB (IRN) red noise\n",
    "assert int_bins >= crn_bins\n",
    "f_intrin = jnp.arange(1/Tspan, (int_bins + 0.01)/Tspan, 1/Tspan) # an array of frequency-bins for the IRN process\n",
    "f_common = f_intrin[:crn_bins] # an array of frequency-bins for the common process\n",
    "renorm_const = 1 # the factor by which the units are going to change (divided by). Set it to `1` for no unit change (seconds), or let it be `1e9` (nano seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ordered_gwb_psd_model_params': array(['halflog10_rho'], dtype='<U13'),\n",
       " 'varied_gwb_psd_params': ['halflog10_rho'],\n",
       " 'gwb_psd_param_lower_lim': Array([-9., -9., -9., -9., -9.], dtype=float32),\n",
       " 'gwb_psd_param_upper_lim': Array([-3.5, -3.5, -3.5, -3.5, -3.5], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_psd_model1, chosen_orf_model1, gwb_helper_dictionary1 = utils.hd_spectrum(renorm_const=renorm_const,crn_bins=crn_bins, lower_halflog10_rho=-9, upper_halflog10_rho=-3.5)\n",
    "gwb_helper_dictionary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = models.UniformPrior(gwb_psd_func = chosen_psd_model1,\n",
    "                orf_func = chosen_orf_model1,\n",
    "                crn_bins = crn_bins,\n",
    "                int_bins = int_bins,\n",
    "                f_common = f_common, \n",
    "                f_intrin = f_intrin,\n",
    "                df = 1/Tspan,\n",
    "                Tspan = Tspan, \n",
    "                Npulsars = len(psrs),\n",
    "                psr_pos = [psr.pos for psr in psrs],\n",
    "                gwb_helper_dictionary = gwb_helper_dictionary1,\n",
    "                gamma_min = 0,\n",
    "                gamma_max = 7,\n",
    "                log10A_min = -20 + 0.5 * jnp.log10(renorm_const), #`0.5 * jnp.log10(renorm_const)` is added to account for change in units,\n",
    "                log10A_max = -11 + 0.5 * jnp.log10(renorm_const), #`0.5 * jnp.log10(renorm_const)` is added to account for change in units,\n",
    "                renorm_const = renorm_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.57506897e+00, -3.32627940e+00,  1.16764147e+01,\n",
       "          7.89285350e+00,  8.84877575e-01, -4.04996640e-03]]),\n",
       " (1, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def astro_prior_func_uniform(xs):\n",
    "    '''\n",
    "    this function does not do anything. Uniform prior is already included in the Bayesian inference object. \n",
    "    So, if you wish to use uniform prior on the astro parameters, this function is what you need.\n",
    "\n",
    "    :param xs: an array of length equal to the number of astro params\n",
    "    '''\n",
    "    return 0\n",
    "astro_prior_bounds = np.array([[0.1, 11.0], \n",
    "          [-3.5, -1.5], \n",
    "          [10.5, 12.5], \n",
    "          [7.6, 9.0], \n",
    "          [0.0, 0.9], \n",
    "          [-1.5, 0.0]])\n",
    "\n",
    "astro_x0 = np.random.uniform( \n",
    "            astro_prior_bounds[:, 0], \n",
    "            astro_prior_bounds[:, 1])[None]\n",
    "astro_x0, astro_x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_294270/435510844.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nf, half_range, B, mean, _, _ = torch.load('../Data/AstroData/PaperFinal/chosenone/lr0.0001_bs1000_decay0/condflow_at_40000.pkl',\n"
     ]
    }
   ],
   "source": [
    "nf, half_range, B, mean, _, _ = torch.load('../Data/AstroData/PaperFinal/chosenone/lr0.0001_bs1000_decay0/condflow_at_40000.pkl',\n",
    "                                            map_location = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_astro_params = 6\n",
    "nf_dist_object = nf_dist.NFastroinference(pyro_nf_object = nf,\n",
    "        mean = np.array(mean),\n",
    "        half_range = np.array(half_range),\n",
    "        scale = B,\n",
    "        gwb_freq_idxs = np.array(range(n_astro_params, n_astro_params + crn_bins), dtype = int),\n",
    "        ast_param_idxs = np.array(range(n_astro_params), dtype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The delta is 1e-06\n",
      "Condition number of the TNT matrix before stabilizing is: 6.03792e+18\n",
      "Condition number of the TNT matrix after stabilizing is: 1.1514395e+17\n"
     ]
    }
   ],
   "source": [
    "m1 = LC.AstroInferenceModel(psrs = psrs,\n",
    "                        nf_dist = nf_dist_object ,\n",
    "                        num_astro_params = n_astro_params,\n",
    "                        astr_prior_lower_lim = astro_prior_bounds[:, 0],\n",
    "                        astr_prior_upper_lim = astro_prior_bounds[:, 1],\n",
    "                        astro_additional_prior_func = astro_prior_func_uniform,\n",
    "                        TNr=jnp.array([False]),\n",
    "                        TNT=jnp.array([False]),\n",
    "                        run_type_object = o1,\n",
    "                        noise_dict = noise_dict, \n",
    "                        backend = 'backend', \n",
    "                        tnequad = False, \n",
    "                        inc_ecorr = True, \n",
    "                        del_pta_after_init = True,\n",
    "                        matrix_stabilization = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is just a demo. You can choose your model 2 to be anythingyou want (within reason!). For example, you can use different NF objects (comparing different simulations) to test which one gives you a higher Bayes Factor.\n",
    "### For now, I just want to show that the HM object and setup is right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = copy.deepcopy(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_object = LC.TwoAstroModelHyperModel(model1=m1, model2=m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8374594911483685"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = hm_object.make_initial_guess(seed = 12123)\n",
    "x0[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([46061.355], dtype=float32), 8.01)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[-1] = .1\n",
    "hm_object.get_lnliklihood(x0), hm_object.get_lnprior(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([46399.69], dtype=float32), 8.01)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[-1] = .9\n",
    "hm_object.get_lnliklihood(x0), hm_object.get_lnprior(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 ms ± 347 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hm_object.get_lnliklihood(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 µs ± 4.63 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hm_object.get_lnprior(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_object.sample(x0 = np.array(x0), niter = int(1e6), savedir = '../testnew/ASTROHM/', \n",
    "         resume=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
